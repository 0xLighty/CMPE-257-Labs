{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/jy2040/tast3-recommender-system?scriptVersionId=94539063\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","source":"1. Download m1.zip file from the link (https://grouplens.org/datasets/movielens/1m/) (0points)","metadata":{}},{"cell_type":"markdown","source":"2. Load the movies and ratings data (1 points)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport warnings\nwarnings.filterwarnings('ignore')\nratings = pd.io.parsers.read_csv('../input/cifar10/ratings.dat', \n    names=['user_id', 'movie_id', 'rating', 'time'], delimiter='::')\nmovies = pd.io.parsers.read_csv('../input/cifar10/movies.dat',\n    names=['movie_id', 'title', 'genre'],encoding='latin-1', delimiter='::')","metadata":{"execution":{"iopub.status.busy":"2022-05-02T05:31:09.295761Z","iopub.execute_input":"2022-05-02T05:31:09.296111Z","iopub.status.idle":"2022-05-02T05:31:14.331462Z","shell.execute_reply.started":"2022-05-02T05:31:09.296018Z","shell.execute_reply":"2022-05-02T05:31:14.33076Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"movies.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-02T05:31:14.332618Z","iopub.execute_input":"2022-05-02T05:31:14.333174Z","iopub.status.idle":"2022-05-02T05:31:14.35048Z","shell.execute_reply.started":"2022-05-02T05:31:14.333135Z","shell.execute_reply":"2022-05-02T05:31:14.34965Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   movie_id                               title                         genre\n0         1                    Toy Story (1995)   Animation|Children's|Comedy\n1         2                      Jumanji (1995)  Adventure|Children's|Fantasy\n2         3             Grumpier Old Men (1995)                Comedy|Romance\n3         4            Waiting to Exhale (1995)                  Comedy|Drama\n4         5  Father of the Bride Part II (1995)                        Comedy","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movie_id</th>\n      <th>title</th>\n      <th>genre</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Toy Story (1995)</td>\n      <td>Animation|Children's|Comedy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Jumanji (1995)</td>\n      <td>Adventure|Children's|Fantasy</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Grumpier Old Men (1995)</td>\n      <td>Comedy|Romance</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Waiting to Exhale (1995)</td>\n      <td>Comedy|Drama</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Father of the Bride Part II (1995)</td>\n      <td>Comedy</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"ratings.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-02T05:31:14.35173Z","iopub.execute_input":"2022-05-02T05:31:14.352154Z","iopub.status.idle":"2022-05-02T05:31:14.367826Z","shell.execute_reply.started":"2022-05-02T05:31:14.352105Z","shell.execute_reply":"2022-05-02T05:31:14.366817Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   user_id  movie_id  rating       time\n0        1      1193       5  978300760\n1        1       661       3  978302109\n2        1       914       3  978301968\n3        1      3408       4  978300275\n4        1      2355       5  978824291","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>movie_id</th>\n      <th>rating</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1193</td>\n      <td>5</td>\n      <td>978300760</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>661</td>\n      <td>3</td>\n      <td>978302109</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>914</td>\n      <td>3</td>\n      <td>978301968</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>3408</td>\n      <td>4</td>\n      <td>978300275</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>2355</td>\n      <td>5</td>\n      <td>978824291</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"3. What do you mean by Singular Value Decomposition (2 points)?","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:31:39.295833Z","iopub.execute_input":"2022-04-29T23:31:39.296891Z","iopub.status.idle":"2022-04-29T23:31:39.310064Z","shell.execute_reply.started":"2022-04-29T23:31:39.296844Z","shell.execute_reply":"2022-04-29T23:31:39.309209Z"}}},{"cell_type":"code","source":"'''\nThe Singular Value Decomposition (SVD) of a matrix is a factorization of that matrix into three matrices\nGiven m X n matrix, A, then SVD convert this matrix into 3 matrices as below...\n\nA = U W V^T\n\nHere, \nU is a mxn matrix of the orthonormal eigenvectors of A A^T              .\nVT is a transpose of a nxn matrix containing the orthonormal eigenvectors of A^T A.\nW is a nxn diagonal matrix of the singular values which are the square roots of the eigenvalues of A^T A.\n\nA (m X n) = U (m X r) X W (r X r) X V^T (r X n)\n\nSVD factorizes the matrix into singular vectors and singular values. It provides the information using the \neigendecomposition\n\nTo understand the SVD first we need to understand the eigenvalues and eigenvector\nVector is produced when we multiply Matrix with a Vector. This multiplication is defined as the transformation of the \nvector w.r.t a matrix in th egiven vector space. However, some vectors for some matrix does not change the direction \nafter the transformation is applied to the vector. Such vectors are called eigenvectors.\nThe scaled values of the vector after transformation is called eigenvalues.\n'''","metadata":{"execution":{"iopub.status.busy":"2022-05-02T05:31:14.37012Z","iopub.execute_input":"2022-05-02T05:31:14.370623Z","iopub.status.idle":"2022-05-02T05:31:14.381231Z","shell.execute_reply.started":"2022-05-02T05:31:14.370575Z","shell.execute_reply":"2022-05-02T05:31:14.380309Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"'\\nThe Singular Value Decomposition (SVD) of a matrix is a factorization of that matrix into three matrices\\nGiven m X n matrix, A, then SVD convert this matrix into 3 matrices as below...\\n\\nA = U W V^T\\n\\nHere, \\nU is a mxn matrix of the orthonormal eigenvectors of A A^T              .\\nVT is a transpose of a nxn matrix containing the orthonormal eigenvectors of A^T A.\\nW is a nxn diagonal matrix of the singular values which are the square roots of the eigenvalues of A^T A.\\n\\nA (m X n) = U (m X r) X W (r X r) X V^T (r X n)\\n\\nSVD factorizes the matrix into singular vectors and singular values. It provides the information using the \\neigendecomposition\\n\\nTo understand the SVD first we need to understand the eigenvalues and eigenvector\\nVector is produced when we multiply Matrix with a Vector. This multiplication is defined as the transformation of the \\nvector w.r.t a matrix in th egiven vector space. However, some vectors for some matrix does not change the direction \\nafter the transformation is applied to the vector. Such vectors are called eigenvectors.\\nThe scaled values of the vector after transformation is called eigenvalues.\\n'"},"metadata":{}}]},{"cell_type":"markdown","source":"4. What do you mean by Principal Component Analysis (2 points)?","metadata":{}},{"cell_type":"code","source":"'''\nPrincipal Component Analysis:\n\nPCA is a dimentional reduction technique used in the machine learning field to tackle the the dataset with many features.\nWhen tackling the machine learning task, it is required that we feed only important features to it. Sometimes there are\ndatasets with 100s of feature and in such scenario it is crucial to get the information about the variables(features) \nwhich directly affects the target variable. And some features are not that important and will burden on the model and will\nmake a model calculation much complex. In this case, we require a dimentionality reduction techniques to extract important\nfeatures.\n\nIn a nutshell, PCA — reduce the number of variables of a data set, while preserving as much information as possible.\n\nMathematically, PCA consist of 3 steps.,\nSTANDARDIZATION : value - mean / standard deviation \nCOMPUTE COVARIANCE MATRIX : To identify the correlation between variables we compute covariance matrix\nCOMPUTE EIGENVALUES AND EIGENVECTORS FROM COVARIANCE MATRIX TO FIND PRINCIPAL COMPONENT\n\nPrincipal components are new variables that are created by combining or mixing the basic variables in a linear way.\nThe new variables (i.e., main components) are uncorrelated, and the majority of the information contained in the initial\nvariables is squeezed or compressed into the first components.\n'''","metadata":{"execution":{"iopub.status.busy":"2022-05-02T05:31:14.383114Z","iopub.execute_input":"2022-05-02T05:31:14.383336Z","iopub.status.idle":"2022-05-02T05:31:14.396594Z","shell.execute_reply.started":"2022-05-02T05:31:14.38331Z","shell.execute_reply":"2022-05-02T05:31:14.395988Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"'\\nPrincipal Component Analysis:\\n\\nPCA is a dimentional reduction technique used in the machine learning field to tackle the the dataset with many features.\\nWhen tackling the machine learning task, it is required that we feed only important features to it. Sometimes there are\\ndatasets with 100s of feature and in such scenario it is crucial to get the information about the variables(features) \\nwhich directly affects the target variable. And some features are not that important and will burden on the model and will\\nmake a model calculation much complex. In this case, we require a dimentionality reduction techniques to extract important\\nfeatures.\\n\\nIn a nutshell, PCA — reduce the number of variables of a data set, while preserving as much information as possible.\\n\\nMathematically, PCA consist of 3 steps.,\\nSTANDARDIZATION : value - mean / standard deviation \\nCOMPUTE COVARIANCE MATRIX : To identify the correlation between variables we compute covariance matrix\\nCOMPUTE EIGENVALUES AND EIGENVECTORS FROM COVARIANCE MATRIX TO FIND PRINCIPAL COMPONENT\\n\\nPrincipal components are new variables that are created by combining or mixing the basic variables in a linear way.\\nThe new variables (i.e., main components) are uncorrelated, and the majority of the information contained in the initial\\nvariables is squeezed or compressed into the first components.\\n'"},"metadata":{}}]},{"cell_type":"markdown","source":"5. Explain content-based vs collaborative recommendation (2 points)","metadata":{}},{"cell_type":"code","source":"'''\nContent Based Recommendation:\nContetnt based recommendation uses features to recommend other items similar to the features what user likes, based on\nuser's previous actions and/or feedbacks.\n\nAll the data provided by the uses either by click events or other entities, are used to provide the recommendation to \nthe user. System improves by taking feedback implicitly whether user went with that recommendation or not and improves\neach time with new data availability.\n\nCollaborative Recommendation:\nThis recommendation process takes input from similar users and provide the recommendation to the the user. The inputs\nusually are what other users like and purchased, view etc.\n\nIt works by searching through a huge group of people and finds the smaller set of users with a similar likings, tastes\nto a particular user. It does so by looking at each items they like and combine them to create a ranked list of\nsuggestions.\n'''","metadata":{"execution":{"iopub.status.busy":"2022-05-02T05:31:14.397802Z","iopub.execute_input":"2022-05-02T05:31:14.398136Z","iopub.status.idle":"2022-05-02T05:31:14.414755Z","shell.execute_reply.started":"2022-05-02T05:31:14.398108Z","shell.execute_reply":"2022-05-02T05:31:14.413887Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"\"\\nContent Based Recommendation:\\nContetnt based recommendation uses features to recommend other items similar to the features what user likes, based on\\nuser's previous actions and/or feedbacks.\\n\\nAll the data provided by the uses either by click events or other entities, are used to provide the recommendation to \\nthe user. System improves by taking feedback implicitly whether user went with that recommendation or not and improves\\neach time with new data availability.\\n\\nCollaborative Recommendation:\\nThis recommendation process takes input from similar users and provide the recommendation to the the user. The inputs\\nusually are what other users like and purchased, view etc.\\n\\nIt works by searching through a huge group of people and finds the smaller set of users with a similar likings, tastes\\nto a particular user. It does so by looking at each items they like and combine them to create a ranked list of\\nsuggestions.\\n\""},"metadata":{}}]},{"cell_type":"markdown","source":"6. Create m x u matrix with movies as row and users as column. Normalize the matrix. (2 points)","metadata":{}},{"cell_type":"code","source":"import numpy as np\nratings_mat = np.ndarray(\n    shape=(np.max(ratings.movie_id.values), np.max(ratings.user_id.values)),\n    dtype=np.uint8)\nratings_mat[ratings.movie_id.values-1, ratings.user_id.values-1] = ratings.rating.values","metadata":{"execution":{"iopub.status.busy":"2022-05-02T05:31:14.415937Z","iopub.execute_input":"2022-05-02T05:31:14.416497Z","iopub.status.idle":"2022-05-02T05:31:14.461074Z","shell.execute_reply.started":"2022-05-02T05:31:14.416459Z","shell.execute_reply":"2022-05-02T05:31:14.460279Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"normalised_mat = ratings_mat - np.asarray([(np.mean(ratings_mat, 1))]).T\nA = normalised_mat.T / np.sqrt(ratings_mat.shape[0] - 1)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T05:31:14.462207Z","iopub.execute_input":"2022-05-02T05:31:14.462539Z","iopub.status.idle":"2022-05-02T05:31:14.658784Z","shell.execute_reply.started":"2022-05-02T05:31:14.462509Z","shell.execute_reply":"2022-05-02T05:31:14.657657Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"7. Perform SVD to get U, S and V (2 points)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:35:09.970188Z","iopub.execute_input":"2022-04-29T23:35:09.970455Z","iopub.status.idle":"2022-04-29T23:35:09.978075Z","shell.execute_reply.started":"2022-04-29T23:35:09.970427Z","shell.execute_reply":"2022-04-29T23:35:09.977332Z"}}},{"cell_type":"code","source":"U, S, V = np.linalg.svd(A)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T05:31:14.660323Z","iopub.execute_input":"2022-05-02T05:31:14.660686Z","iopub.status.idle":"2022-05-02T05:32:02.305683Z","shell.execute_reply.started":"2022-05-02T05:31:14.660635Z","shell.execute_reply":"2022-05-02T05:32:02.304632Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"8. Select top 50 components from V.T (1 point)","metadata":{}},{"cell_type":"code","source":"def top_cosine_similarity(data, movie_id, top_n=10):\n    index = movie_id - 1 # Movie id starts from 1\n    movie_row = data[index, :]\n    magnitude = np.sqrt(np.einsum('ij, ij -> i', data, data))\n    similarity = np.dot(movie_row, data.T) / (magnitude[index] * magnitude)\n    sort_indexes = np.argsort(-similarity)\n    return sort_indexes[:top_n]\n\n# Helper function to print top N similar movies\ndef print_similar_movies(movie_data, movie_id, top_indexes):\n    print('Recommendations for {0}: \\n'.format(\n    movie_data[movie_data.movie_id == movie_id].title.values[0]))\n    for id in top_indexes + 1:\n        print(movie_data[movie_data.movie_id == id].title.values[0])","metadata":{"execution":{"iopub.status.busy":"2022-05-02T05:32:02.308684Z","iopub.execute_input":"2022-05-02T05:32:02.309026Z","iopub.status.idle":"2022-05-02T05:32:02.317698Z","shell.execute_reply.started":"2022-05-02T05:32:02.308979Z","shell.execute_reply":"2022-05-02T05:32:02.316499Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# top 50 components from V.T\nk = 50\nmovie_id = 10 # Grab an id from movies.dat\ntop_n = 10\n\nsliced_svd = V.T[:, :k] # representative data","metadata":{"execution":{"iopub.status.busy":"2022-05-02T05:32:02.319246Z","iopub.execute_input":"2022-05-02T05:32:02.319931Z","iopub.status.idle":"2022-05-02T05:32:02.328231Z","shell.execute_reply.started":"2022-05-02T05:32:02.31964Z","shell.execute_reply":"2022-05-02T05:32:02.327094Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"9. Calculate the covariance matrix for the entire dataset (from step 6) (1 point)","metadata":{}},{"cell_type":"code","source":"normalised_mat = ratings_mat - np.matrix(np.mean(ratings_mat, 1)).T\ncov_mat = np.cov(normalised_mat)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T05:32:02.329802Z","iopub.execute_input":"2022-05-02T05:32:02.330342Z","iopub.status.idle":"2022-05-02T05:32:04.129209Z","shell.execute_reply.started":"2022-05-02T05:32:02.330306Z","shell.execute_reply":"2022-05-02T05:32:04.128255Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"cov_mat","metadata":{"execution":{"iopub.status.busy":"2022-05-02T05:32:04.134627Z","iopub.execute_input":"2022-05-02T05:32:04.137501Z","iopub.status.idle":"2022-05-02T05:32:04.149901Z","shell.execute_reply.started":"2022-05-02T05:32:04.137406Z","shell.execute_reply":"2022-05-02T05:32:04.148965Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"array([[ 6.04861787e+01,  4.95198538e-01,  1.76929484e-01, ...,\n        -4.93522594e-01, -5.68650680e-01, -7.19071866e-01],\n       [ 4.95198538e-01,  1.16348766e+00,  1.58844772e-01, ...,\n        -3.34840863e-01, -3.77743124e-01, -4.15482696e-01],\n       [ 1.76929484e-01,  1.58844772e-01,  7.54054386e-01, ...,\n         6.03117814e-02,  1.28845287e-01,  8.97416791e-02],\n       ...,\n       [-4.93522594e-01, -3.34840863e-01,  6.03117814e-02, ...,\n         1.48886377e+02,  1.66240086e+02,  1.87242809e+02],\n       [-5.68650680e-01, -3.77743124e-01,  1.28845287e-01, ...,\n         1.66240086e+02,  1.91668473e+02,  2.15138152e+02],\n       [-7.19071866e-01, -4.15482696e-01,  8.97416791e-02, ...,\n         1.87242809e+02,  2.15138152e+02,  2.61565528e+02]])"},"metadata":{}}]},{"cell_type":"markdown","source":"10. Get the eigen vectors from the covariance matrix (1 point)","metadata":{}},{"cell_type":"code","source":"evals, evecs = np.linalg.eig(cov_mat)\nprint(evecs)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T05:32:04.155294Z","iopub.execute_input":"2022-05-02T05:32:04.15819Z","iopub.status.idle":"2022-05-02T05:32:41.977266Z","shell.execute_reply.started":"2022-05-02T05:32:04.158123Z","shell.execute_reply":"2022-05-02T05:32:41.976425Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"[[-7.98555372e-07 -7.79883561e-05 -7.75749026e-07 ...  0.00000000e+00\n   0.00000000e+00  0.00000000e+00]\n [-4.76718261e-06 -4.11439812e-05 -1.63188619e-06 ...  0.00000000e+00\n   0.00000000e+00  0.00000000e+00]\n [ 6.86734565e-06 -1.46972260e-05 -4.88584335e-06 ...  0.00000000e+00\n   0.00000000e+00  0.00000000e+00]\n ...\n [ 3.85226405e-03 -8.49556844e-05  2.46591312e-04 ...  0.00000000e+00\n   0.00000000e+00  0.00000000e+00]\n [ 4.48144954e-03  4.84747933e-04  2.20442033e-04 ...  0.00000000e+00\n   0.00000000e+00  0.00000000e+00]\n [ 5.16942174e-03  1.34551897e-03  1.88997866e-04 ...  0.00000000e+00\n   0.00000000e+00  0.00000000e+00]]\n","output_type":"stream"}]},{"cell_type":"code","source":"evecs","metadata":{"execution":{"iopub.status.busy":"2022-05-02T05:32:41.978936Z","iopub.execute_input":"2022-05-02T05:32:41.979431Z","iopub.status.idle":"2022-05-02T05:32:41.986746Z","shell.execute_reply.started":"2022-05-02T05:32:41.979387Z","shell.execute_reply":"2022-05-02T05:32:41.985791Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"array([[-7.98555372e-07, -7.79883561e-05, -7.75749026e-07, ...,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n       [-4.76718261e-06, -4.11439812e-05, -1.63188619e-06, ...,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n       [ 6.86734565e-06, -1.46972260e-05, -4.88584335e-06, ...,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n       ...,\n       [ 3.85226405e-03, -8.49556844e-05,  2.46591312e-04, ...,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n       [ 4.48144954e-03,  4.84747933e-04,  2.20442033e-04, ...,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n       [ 5.16942174e-03,  1.34551897e-03,  1.88997866e-04, ...,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00]])"},"metadata":{}}]},{"cell_type":"markdown","source":"11. Get the top 50 eigen vectors using eigen values (1 point)","metadata":{}},{"cell_type":"code","source":"k = 50\nmovie_id = 10 # Grab an id from movies.dat\ntop_n = 10\nsliced_pca = evecs[:, :k] # representative data\nprint(\"Top 50 eigen vectors...\\n\",sliced_pca)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T05:32:41.987887Z","iopub.execute_input":"2022-05-02T05:32:41.988114Z","iopub.status.idle":"2022-05-02T05:32:41.999655Z","shell.execute_reply.started":"2022-05-02T05:32:41.988088Z","shell.execute_reply":"2022-05-02T05:32:41.998803Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Top 50 eigen vectors...\n [[-7.98555372e-07 -7.79883561e-05 -7.75749026e-07 ... -3.81357010e-04\n  -7.84644781e-04  4.88390086e-03]\n [-4.76718261e-06 -4.11439812e-05 -1.63188619e-06 ... -1.07537357e-04\n   3.74153269e-04 -4.48565491e-04]\n [ 6.86734565e-06 -1.46972260e-05 -4.88584335e-06 ... -3.14119273e-04\n  -7.14868977e-07 -7.75480561e-05]\n ...\n [ 3.85226405e-03 -8.49556844e-05  2.46591312e-04 ... -8.15233890e-04\n   5.40643437e-04  5.31461597e-04]\n [ 4.48144954e-03  4.84747933e-04  2.20442033e-04 ... -7.42068360e-04\n   4.72259775e-04  4.32795683e-04]\n [ 5.16942174e-03  1.34551897e-03  1.88997866e-04 ... -4.78937974e-04\n   6.45360114e-04  3.85102269e-04]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"12. Using cosine similarity find 10 closest movies using the 50 components from SVD (step 8) (2 points)","metadata":{}},{"cell_type":"code","source":"top_indexes = top_cosine_similarity(sliced_svd, movie_id, top_n)\nprint_similar_movies(movies, movie_id, top_indexes)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T05:32:42.001131Z","iopub.execute_input":"2022-05-02T05:32:42.001712Z","iopub.status.idle":"2022-05-02T05:32:42.031405Z","shell.execute_reply.started":"2022-05-02T05:32:42.001666Z","shell.execute_reply":"2022-05-02T05:32:42.030479Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Recommendations for GoldenEye (1995): \n\nGoldenEye (1995)\nBroken Arrow (1996)\nDie Hard: With a Vengeance (1995)\nRumble in the Bronx (1995)\nDesperado (1995)\nBatman Forever (1995)\nBad Boys (1995)\nMortal Kombat (1995)\nCutthroat Island (1995)\nCongo (1995)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"13. Using cosine similarity find 10 closest movies using the 50 components from PCA (step 11) (2 points)","metadata":{}},{"cell_type":"code","source":"top_indexes = top_cosine_similarity(sliced_pca, movie_id, top_n)\nprint_similar_movies(movies, movie_id, top_indexes)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T05:32:42.03675Z","iopub.execute_input":"2022-05-02T05:32:42.037582Z","iopub.status.idle":"2022-05-02T05:32:42.065876Z","shell.execute_reply.started":"2022-05-02T05:32:42.037513Z","shell.execute_reply":"2022-05-02T05:32:42.064924Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Recommendations for GoldenEye (1995): \n\nGoldenEye (1995)\nBroken Arrow (1996)\nDie Hard: With a Vengeance (1995)\nRumble in the Bronx (1995)\nDesperado (1995)\nBatman Forever (1995)\nBad Boys (1995)\nMortal Kombat (1995)\nCutthroat Island (1995)\nCongo (1995)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"14. Compare the results of above two methods (1 point)","metadata":{}},{"cell_type":"code","source":"'''\nRecommendations were same for both PCA and SVD techniques.\nTwo movies which were used for the prediction has 10 as id in the dataset\nTop 10 recommendations were same.\n'''","metadata":{"execution":{"iopub.status.busy":"2022-05-02T05:32:42.071202Z","iopub.execute_input":"2022-05-02T05:32:42.074645Z","iopub.status.idle":"2022-05-02T05:32:42.086386Z","shell.execute_reply.started":"2022-05-02T05:32:42.074573Z","shell.execute_reply":"2022-05-02T05:32:42.085266Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"'\\nRecommendations were same for both PCA and SVD techniques.\\nTwo movies which were used for the prediction has 10 as id in the dataset\\nTop 10 recommendations were same.\\n'"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}